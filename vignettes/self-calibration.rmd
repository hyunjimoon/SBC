---
title: "self-calibration"
author: "Hyunji Moon, Shinyoung Kim"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(SBC) #devtools::install_github("hyunjimoon/SBC")
library(cmdstanr)
library(parallel)
library(bayesplot)
library(posterior)
library(dplyr)
library(future)
library(ggpubr)
library(mclust)
library(rstanarm)
options(mc.cores = parallel::detectCores())
plan(multisession)
options(SBC.min_chunk_size = 5)
set.seed(1984)
devtools::load_all()
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  include = TRUE,  cache = FALSE,  collapse = TRUE,  echo = TRUE,
  message = FALSE, tidy = FALSE,  warning = FALSE,   comment = "  ",
  dev = "png", dev.args = list(bg = '#FFFFF8'), dpi = 300,
  fig.align = "center",  fig.width = 7,  fig.asp = 0.618,  fig.show = "hold",
  out.width = "90%")
```

```{r}
#_poisson, _logistic with transform_type  = "log", / family 
generator_gmm <- function(mixture_means, mixture_sds, fixed_sim_args){
  # fixed value across simulated datasets
  ## meta
  nobs <- fixed_sim_args$nobs
  ndraws <- fixed_sim_args$ndraws
  transform_types <- fixed_sim_args$transform_types
  link_type <- fixed_sim_args$link_type
  ## distribution-specific
  shape <- fixed_sim_args$shape 
  
  # predictor
  if("X" %in% names(fixed_sim_args)) {X = fixed_sim_args$X} else X = 0
  # parameter with fixed distribution across `nsims` datasets
  if("b" %in% names(fixed_sim_args)) {b <- fixed_sim_args$b}  else b = 0
  # target variable updated at each iteration
  a <- invtf_param_vec(rvar_rng(rnorm, n = 1, mean = sample(mixture_means$a, 1, replace=TRUE), sd=mixture_sds$a, ndraws = nsims), tf = transform_types$a)

  # generate
  mu = draws_of(a + X %**% b)
  if(link_type == "log"){
        mu =  exp(mu) 
  }else if(link_type == "logit"){
        mu <- invlogit(mu)
  }
  Y <- rvar_rng(rbinom, n = nobs, size = nsize, prob = mu, ndraws = nsims) 
  if(any(is.na(Y))) print(mu) 
  gen_rvars <- draws_rvars(nsims = nsims, nobs = nobs, nsize = nsize,
                           mixture_means = mixture_means$a, mixture_sds = mixture_sds$a, 
                           Y = Y)
  SBC_datasets(
    parameters = as_draws_matrix(list(a = a)), 
    generated = draws_rvars_to_standata(gen_rvars)
  )
}
nsims = 30
nobs = 100
ndraws = 1000
nsize = 2
npredictors = 15
ntarget_params = 1
chains = 4
transform_types = list(a = "identity") # parameter constraint in stan translated to generator (e.g. bound, simplex)
fixed_sim_args <- list(nobs = nobs, ndraws = ndraws, nsize = nsize, link_type = "logit", transform_types = transform_types, shape = 1,  b = rvar_rng(rnorm, ndraws = 1, n = npredictors, 0, 1), X = rvar(array(rnorm(n = nobs * npredictors, mean = 1, sd = 1), dim = c(1, nobs, npredictors))))

# proxy for target variable
mixture_means = draws_rvars(a = rvar(array(rep(rnorm(nsims, 2, 5), each = nsims), dim = c(nsims, nsims))))
mixture_sds = draws_rvars(a = rvar(array(rep(1, nsims), dim=c(nsims, 1))))

datasets_25 <- generator_gmm(
  mixture_means = mixture_means,
  mixture_sds = mixture_sds,
  fixed_sim_args = fixed_sim_args
)

#mod_gmm <- cmdstanr::cmdstan_model("./models/gamma-reg_gmm.stan")
mod_gmm <- cmdstanr::cmdstan_model("./models/binom-laplace_gmm.stan")
backend_hmc_gmm <- SBC_backend_cmdstan_sample(mod_gmm, chains = chains, iter_sampling = ndraws / chains)
```

Starting from a bad SBC plot (first), better SBC plot (second) is found after three iterations.
```{r}
result_25_hmc <- compute_results(datasets_25, backend_hmc_gmm, thin_ranks = 3)
plot_rank_hist(result_25_hmc)

# self-calibrate
param_sc_hmc <- self_calib(generator_gmm, backend_hmc_gmm, mixture_means, mixture_sds, nsims_fn = function(...){nsims}, thin = 3, transform_types = transform_types, fixed_generator_args = list(fixed_sim_args = fixed_sim_args))
plot_rank_hist(param_sc_hmc)
```

For ADVI, $N(2,5^2)$ for the coefficient breaks in every case and therefore $N(2,1^2)$ is used. Notice as the self-consistent parameter region is a function of a generator and inference engine; prior $N(2,5^2)$ or $N(2,1^2)$ is simply used as an initial distribution. It remains to be seen whether different initial distribution converge to near enough region (near uniqueness). 

```{r}
mixture_means_21 = draws_rvars(a = rvar(array(rep(rnorm(nsims, 2, 1), each = nsims), dim = c(nsims, nsims))))
datasets_21 <- generator_gmm(
  mixture_means = mixture_means_21,
  mixture_sds = mixture_sds,
  fixed_values = fixed_values
)

backend_vi <- SBC_backend_cmdstan_variational(mod_gmm, output_samples = ndraws, algorithm = "fullrank")
result_21_vi <- compute_results(datasets_21, backend_vi, thin_ranks = 1)
plot_rank_hist(result_21_vi)

# self-calibrate
param_sc_vi <- self_calib(generator_gmm, backend_vi, mixture_means_21, mixture_sds, nsims_fn = function(...){nsims}, thin = 1, fixed_generator_args = list(fixed_values = fixed_values, ))
plot_rank_hist(param_sc_vi)
```

```{r}
plot_ecdf_diff(param_sc_vi)
plot_ecdf_diff(result_21_vi)
```
