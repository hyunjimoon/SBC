---
title: "self-calibration-adaptive"
author: "Hyunji Moon, Shinyoung Kim"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE, warning=FALSE}
library(SBC)
library(cmdstanr)
library(parallel)
library(bayesplot)
library(posterior)
library(dplyr)
library(rstan)
library(future)
library(ggpubr)
library(rstanarm)
library(ggplot2)
library(mclust)
library(plot3D)
library(nloptr)
options(mc.cores = parallel::detectCores())
plan(multisession)
options(SBC.min_chunk_size = 5)
#set.seed(1984)
```


```{R, warning=FALSE, error=FALSE}
## Generator settings
# number of SBC simulations per iteration (generator)
nsims <- 200

# number of observations
nobs <- 10#2

# link function (1 = logit, 2 = probit, 3 = cloglog)
link <- 1

# number of binomial trials per observation
nsize <- 10

## Backend settings
# number of draws per posterior approximation 
ndraws <- 100

# number of chains for hmc posterior approximation
nchains <- 2
```

# Inspecting DAP of binom-laplace 
```{R, warning=FALSE, error=FALSE}
generator_binom <- function(lambdas, fixed_args){
  # fixed value across simulated datasets
  # experiment settings
  nobs <- fixed_args$nobs
  nsize <- fixed_args$nsize
  dist_types <- fixed_args$dist_types
  # modular settings
  link_type <- fixed_args$link_type
  
  # generate
  lambda_arg1 <- c()
  lambda_arg2 <- c()
  if(dist_types$eta == "normal"){
    eta <- rnorm(1, mean = lambdas$eta$mu, sd=lambdas$eta$sigma)
    lambda_arg1 <- c(lambda_arg1, lambdas$eta$mu)
    lambda_arg2 <- c(lambda_arg2, lambdas$eta$sigma)
  }
  else if(dist_types$eta == "gamma"){
    eta <- rgamma(1, shape = lambdas$eta$alpha, rate = lambdas$eta$beta)
    lambda_arg1 <- c(lambda_arg1, lambdas$eta$alpha)
    lambda_arg2 <- c(lambda_arg2, lambdas$eta$beta)
  }
  
  
    
  mu <- invtf_param_vec(eta, link_type = link_type)
  Y <- rbinom(nobs, size = nsize, prob = mu) 
  list(
    parameters = list(eta = eta),
    generated = list(nobs= nobs, nsize = nsize, link = link_type,
                     dist_types = match(unlist(dist_types), c("normal", "gamma")), lambda_arg1 = lambda_arg1, lambda_arg2 = lambda_arg2, 
                     Y = Y)
  )
}

fixed_args_binom <- list(nobs = nobs, nsize = nsize, link_type = 1, nsims = nsims, ndraws = ndraws, dist_types=list(eta="normal"))

```

```{R, warning=FALSE, error=FALSE}
# initial prior hyperparameters
lambda_init_binom <- list(
  eta = list(mu=100, sigma=100)
)
datasets_binom <- generate_datasets(SBC_generator_function(generator_binom, lambda_init_binom, fixed_args_binom), n_datasets = fixed_args_binom$nsims)

# hyperparameter update algorithm 
updator = "mc_update"

# maximal number of SBC iterations
niter <- 100

# tolerance
tol <- 0.1

# learning rate
gamma <- 1.5 # 0.5 for gradient update, 10 for normal_str_update

# step2: inferring posterior
rstan_binom_mod <- stan_model("models/binom-laplace.stan")
cmdstan_binom_mod <- cmdstanr::cmdstan_model("models/binom-laplace.stan")

backend_binom_opt <- SBC_backend_rstan_optimizing(rstan_binom_mod, draws = ndraws)
#backend_binom_hmc <- SBC_backend_cmdstan_sample(cmdstan_binom_mod, chains = 4, iter_sampling = ndraws / 4) # thin = 10
calib_generator <- function(lambdas, fixed_args){
  generate_datasets(SBC_generator_function(generator_binom, lambdas, fixed_args), n_datasets = fixed_args$nsims)
}

calculate_dap <- function(mu, var, generator, backened, fixed_args){
  lambda_init_binom <- list(
    eta = list(mu=mu, sigma=sqrt(var))
  )
  datasets <- do.call(generator, list(lambda_init_binom, fixed_args = fixed_args))
  sbc_result <- compute_results(datasets, backened, thin_ranks = 1)
  draws_eta <- c()
  for(fit in sbc_result$fits){
    samples <- SBC_fit_to_draws_matrix(fit)
    draws_eta <- c(draws_eta, posterior::extract_variable(samples, "eta"))
  }
  # assume normal for dap
  mu <- mean(draws_eta)
  var <- sd(draws_eta)^2
  return(list(mu=mu, var=var, draws_eta=draws_eta))
}

```

##

```{r}
mu_seq <- seq(0, 5, length.out = 5)
var_seq <- seq(1, 25, length.out = 5)
grid_size <- length(mu_seq) * length(var_seq)
contraction_arr <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
rownames(contraction_arr) <- mu_seq
colnames(contraction_arr) <- var_seq
for(i in 1:length(mu_seq)){
  for(j in 1:length(var_seq)){
    dap <- calculate_dap(mu_seq[[i]],var_seq[[j]] , calib_generator, backend_binom_opt, fixed_args_binom)
    dapdap <- calculate_dap(dap$mu, dap$var, calib_generator, backend_binom_opt, fixed_args_binom)
    contraction_arr[i,j] <- (mu_seq[[i]] - dap$mu)^2 + (var_seq[[j]] - dap$var)^2# - ((dap$mu- dapdap$mu)^2 + (dap$var - dapdap$var)^2)
  }
}
```


```{R}
persp3D(x=mu_seq, y=var_seq, z = contraction_arr, theta=55, phi=10, xlab="mu", ylab="var", zlab="convex if ", ticks=5, ticktype="detailed")

```

Define simplex transformation functions
https://github.com/stan-dev/math/blob/develop/stan/math/prim/fun/simplex_constrain.hpp
https://github.com/stan-dev/math/blob/develop/stan/math/prim/fun/simplex_free.hpp

```{r}
to_simplex <- function(unconstrained){
  # input vector size K
  # output vector size K + 1
  Km1 <- length(unconstrained)
  x <- c()
  stick_len <- 1.0
  for(k in 0:(Km1 - 1)){
    z <- rstanarm::invlogit(unconstrained[k + 1] - log(Km1 - k))
    x[k + 1] <- stick_len * z
    stick_len <- stick_len - x[k + 1]
  }
  x[Km1 + 1] <- stick_len
  return(x)
}

unconstrain_simplex <- function(simplex){
  # input vector size K
  # output vector size K - 1
  y <- c()
  Km1 = length(simplex) - 1
  stick_len <- simplex[Km1 + 1]
  for(k in (Km1 - 1):0){
    stick_len <- stick_len + simplex[k + 1]
    z_k <- simplex[k + 1] / stick_len
    y[k + 1] <- rstanarm::logit(z_k) + log(Km1 - k)
  }
  return(y)
}

```

Define objective and constraint functions

```{R}
# maximize entropy
# partial derivative is: -log p_w - 1
calc_entropy <- function(p){
  return(as.numeric((p + 1e-8) %*% -log(p + 1e-8)) - 100 * (sum(p) - 1)^2)
}

calc_entropy_grad <- function(p){
  return(-log(p + 1e-8) - 1 - 200 * (p + 1e-8))
}

# equal to minimize negative entropy
neg_entropy <- function(p){
  return(-calc_entropy(p))
}

neg_entropy_grad <- function(p){
  return(-calc_entropy_grad(p))
}

theta <- 14
# partial derivative is contraction_arr_{w}
p_v_product_constraint <- function(p){
  # equality constraint should equal 0
  return(as.numeric(p %*% as.vector(contraction_arr)) - 7)
}

p_v_product_constraint_grad <- function(p){
  return(as.vector(contraction_arr))
}
```

Generate initial parameters

```{R}
# calculate theta and p_init
# start at uniform
p_v_dot <- as.numeric(c(1, rep(0, grid_size - 1)) %*% as.vector(contraction_arr))

theta <- p_v_dot

p_unconstrained_init <- unconstrain_simplex(rep(1 / grid_size, grid_size))
# unconstrained param
```

## Run optimization on R^n

```{R}
unconstrained_objective <- function(unconstrained_p){
  p <- to_simplex(unconstrained_p)
  return(neg_entropy(p))
}

unconstrained_eq_constraint <- function(unconstrained_p){
  p <- to_simplex(unconstrained_p)
  return(equality_constraint(p))
}

#If you want to use equality constraints, then you should use one of these algorithms NLOPT_LD_AUGLAG, NLOPT_LN_AUGLAG, NLOPT_LD_AUGLAG_EQ, NLOPT_LN_AUGLAG_EQ, NLOPT_GN_ISRES, NLOPT_LD_SLSQP

unconstrained_opts <- list(algorithm="NLOPT_GN_ISRES", local_opts = list(algorithm="NLOPT_GN_ISRES"), print_level=3)
nloptr::nloptr(p_unconstrained_init, unconstrained_objective, eval_g_eq = unconstrained_eq_constraint, opts = unconstrained_opts)
```
## Run optimization on probability simplex
```{R}
#p_init <- rep(1 / grid_size, grid_size)
p_init <- as.numeric(c(rep(1e-8, grid_size - 1), 1))
# partial derivative is 1
probability_simplex_constraint <- function(p) {
  return(sum(p) - 1)
}

probability_simplex_constraint_grad <- function(p){
  return(rep(1, length(p)))
}


prob_ineq_constraints <- function(p){
  # constraints <- c(p_v_product_constraint(p), probability_simplex_constraint(p))
  # grad <- c(p_v_product_constraint_grad(p), probability_simplex_constraint_grad(p))
  constraints <- c(p_v_product_constraint(p))
  grad <- c(p_v_product_constraint_grad(p))
  return( list(constraints=constraints, jacobian=grad) )
}

#If you want to use equality constraints, then you should use one of these algorithms NLOPT_LD_AUGLAG, NLOPT_LN_AUGLAG, NLOPT_LD_AUGLAG_EQ, NLOPT_LN_AUGLAG_EQ, NLOPT_GN_ISRES, NLOPT_LD_SLSQP

probability_simplex_opts <- list(algorithm="NLOPT_LD_SLSQP", print_level=3, xtol_rel=1e-8, maxeval=1000)
prob_lb <- rep(0.0, length(p_init))
prob_ub <- rep(1.0, length(p_init))
prob_opt <- nloptr::nloptr(p_init, 
                           neg_entropy, 
                           eval_grad_f = neg_entropy_grad, 
                           eval_g_ineq = prob_ineq_constraints, 
                           opts = probability_simplex_opts, 
                           lb=prob_lb, ub=prob_ub)
```

```{R}

result_out <- array(prob_opt$solution, dim = c(length(mu_seq), length(var_seq)))
rownames(result_out) <- mu_seq
colnames(result_out) <- var_seq
persp3D(x=mu_seq, y=var_seq, z = result_out, theta=55, phi=10, xlab="mu", ylab="var", zlab="prob_opt_result", ticks=5, ticktype="detailed")
persp3D(x=mu_seq, y=var_seq, z = contraction_arr, theta=25, phi=10, xlab="mu", ylab="var", zlab="convex if ", ticks=5, ticktype="detailed")
```
