---
title: "SBC with discrete parameters"
author: "Martin ModrÃ¡k"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: yes
vignette: >
  %\VignetteIndexEntry{SBC with discrete parameters}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

SBC was primarily designed for continuous parameters, but can be used
with models that have discrete parameters - whether the parameters
are directly represented (e.g. in JAGS) or marginalized out (as is usual in Stan).

```{r setup, message=FALSE,warning=FALSE, results="hide"}
library(SBC); 
library(ggplot2)

use_cmdstanr <- TRUE # Set to false to use rstan instead

if(use_cmdstanr) {
  library(cmdstanr)
} else {
  library(rstan)
}

# Multiprocessing support
library(future)
plan(multisession)

# The fits are very fast and we fit just a few, 
# so we force a minimum chunk size to reduce overhead of
# paralellization and decrease computation time.
options(SBC.min_chunk_size = 5)

# Setup caching of results
cache_dir <- "./discrete_params_SBC_cache"
if(!dir.exists(cache_dir)) {
  dir.create(cache_dir)
}

```

Model from:
https://mc-stan.org/docs/2_26/stan-users-guide/change-point-section.html

```{r, comment = ""}
cat(readLines("stan/discrete_params1.stan"), sep = "\n")
```

```{r}
if(use_cmdstanr) {
  model_1 <- cmdstan_model("stan/discrete_params1.stan")
  backend_1 <- SBC_backend_cmdstan_sample(model_1)
} else {
  model_1 <- stan_model("stan/discrete_params1.stan")
  backend_1 <- SBC_backend_rstan_sample(model_1)
}
```

Now, let's generate data from the model.

```{r}
generate_single_dataset_1 <- function(T, r_e, r_l) {
  e <- rexp(1, r_e)
  l <- rexp(1, r_l)
  s <- sample.int(T, size = 1)
  
  y <- array(NA_real_, T)
  for(t in 1:T) {
    if(t <= s) {
      rate <- e
    } else {
      rate <- l
    }
    y[t] <- rpois(1, rate) 
  }
  
  list(
    parameters = list(
      e = e, l = l, s = s
    ), generated = list(
      T = T,
      r_e = r_e,
      r_l = r_l,
      y = y
    )
  )
}

generator_1 <- SBC_generator_function(generate_single_dataset_1, T = 5, r_e = 0.5, r_l = 0.1)
```


```{r}
set.seed(85394672)
datasets_1 <- generate_datasets(generator_1, 30)

```

```{r}
results_1 <- compute_results(datasets_1, backend_1, 
                    cache_mode = "results", 
                    cache_location = file.path(cache_dir, "model1"))
```

Here we also use the caching feature to avoid recomputing the fits when recompiling this vignette. 
In practice, caching is not necessary but is often useful.

TODO the diagnostics are false positives, because Rhat and ESS don't work very well for discrete parameters.
We need to figure out how to handle this better.

We can quickly note that the statistics for the `s` parameter are extreme - many ranks of 0 and _extreme_ z-scores, including -Infinity. Seing just one or two such fits should be enough to convince us that there is something fundamentally wrong.

```{r}
dplyr::filter(results_1$stats, parameter == "s") 
```


Inspecting the statistics shows that quite often, the model is quite sure of the value of `s` while the simulated value is just one less. 

Looking at the `ecdf_diff` plot we see that this seems to compromise heavily the inference for `s`, but the other parameters do not show such bad behaviour.

```{r results1_plots}
plot_ecdf_diff(results_1)
plot_rank_hist(results_1)
```

So what happened? After some inspection, you may notice that the simulator does not match the model - the model takes the early rate (`e`) for points `t < s` while the simulator takes `e` for points `t <=  s`, so there is effectively a shift by one time point between the simulator and the model. So let's assume that we beleive that the Stan model is in fact right. We therfore updated the simulator to match the model:


```{r}
generate_single_dataset_2 <- function(T, r_e, r_l) {
  e <- rexp(1, r_e)
  l <- rexp(1, r_l)
  s <- sample.int(T, size = 1)
  
  y <- array(NA_real_, T)
  for(t in 1:T) {
    if(t < s) { ### <--- Only change here
      rate <- e
    } else {
      rate <- l
    }
    y[t] <- rpois(1, rate) 
  }
  
  list(
    parameters = list(
      e = e, l = l, s = s
    ), generated = list(
      T = T,
      r_e = r_e,
      r_l = r_l,
      y = y
    )
  )
}

generator_2 <- SBC_generator_function(generate_single_dataset_2, T = 5, r_e = 0.5, r_l = 0.1)
```



```{r}
set.seed(5846502)
datasets_2 <- generate_datasets(generator_2, 30)
results_2 <- compute_results(datasets_2, backend_1, 
                    cache_mode = "results", 
                    cache_location = file.path(cache_dir, "model2"))
```

```{r results_2_plots}
plot_rank_hist(results_2)
plot_ecdf_diff(results_2)
```


Looks good, so let us add some more SBC steps to make sure the model behaves well.

```{r}
set.seed(54321488)
datasets_3 <- generate_datasets(generator_2, 100)
results_3 <- compute_results(datasets_3, backend_1)

results_all <- bind_results(results_2, results_3)
```

```{r results_all_plots}
plot_rank_hist(results_all)
plot_ecdf_diff(results_all)
```


Now - as far as this amount of SBC steps can see, the model is good and we get good behaviour for both the continuous and the discrete parameters.

