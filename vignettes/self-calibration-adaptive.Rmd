---
title: "self-calibration-adaptive"
author: "Hyunji Moon, Shinyoung Kim"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE, warning=FALSE}
library(SBC)
library(cmdstanr)
library(parallel)
library(bayesplot)
library(posterior)
library(dplyr)
library(rstan)
library(future)
library(ggpubr)
library(rstanarm)
library(ggplot2)
library(mclust)
options(mc.cores = parallel::detectCores())
plan(multisession)
options(SBC.min_chunk_size = 5)
set.seed(1984)
```

```{R}
## Generator settings
# number of SBC simulations per iteration (generator)
nsims <- 80

# number of observations
nobs <- 2

# link function (1 = logit, 2 = probit, 3 = cloglog)
link <- 1

# number of binomial trials per observation
nsize <- 10

## Backend settings
# number of draws per posterior approximation 
ndraws <- 100

# number of chains for hmc posterior approximation
nchains <- 2
```

```{r, warning=FALSE, error=FALSE}
# step1: inferring posterior
generator_binom <- function(lambda_mu, lambda_sigma, fixed_args){
  # fixed value across simulated datasets
  # experiment settings
  nobs <- fixed_args$nobs
  nsize <- fixed_args$nsize
  # modular settings
  link_type <- fixed_args$link_type

  # generate
  eta <- rnorm(1, mean = lambda_mu, sd=lambda_sigma)
  mu <- invtf_param_vec(eta, link_type = link_type)
  Y <- rbinom(nobs, size = nsize, prob = mu) 
  list(
    parameters = list(eta = eta),
    generated = list(nobs= nobs, nsize = nsize, link = link_type,
                     lambda_mu = lambda_mu, lambda_log_sigma = log(lambda_sigma), 
                     Y = Y)
  )
}
fixed_args_binom <- list(nobs = nobs, nsize = nsize, link_type = 1, nsims = nsims, ndraws = ndraws)

# initial prior hyperparameters
lambda_mu <- 1
lambda_sigma <- 10

datasets_binom <- generate_datasets(SBC_generator_function(generator_binom, lambda_mu, lambda_sigma, fixed_args_binom), n_datasets = fixed_args_binom$nsims)
```

```{R}
## Self-calib settings

# hyperparameter update algorithm 
updator = "gradient"

# maximal number of SBC iterations
niter <- 100

# tolerance
tol <- 0.02

# learning rate
gamma <- 0.5

# step2: inferring posterior
#rstan_binom_mod <- stan_model("models/binom-laplace.stan")
cmdstan_binom_mod <- cmdstanr::cmdstan_model("models/binom-laplace.stan")

backend_binom_opt <- SBC_backend_rstan_optimizing(rstan_binom_mod, draws = ndraws)
backend_binom_hmc <- SBC_backend_cmdstan_sample(cmdstan_binom_mod, chains = 4, iter_sampling = ndraws / 4) # thin = 10

# initial badly calibrated
result_binom_opt <- compute_results(datasets_binom, backend_binom_opt, thin_ranks = 1)
plot_rank_hist(result_binom_opt)
# result_binom_hmc <- compute_results(datasets_binom, backend_binom_hmc)

# step3: updating hyperparmeters
# wrapper function to follow `self_calib_adaptive` interface
calib_generator <- function(lambda_mu, lambda_sigma, fixed_args){
  generate_datasets(SBC_generator_function(generator_binom, lambda_mu, lambda_sigma, fixed_args), n_datasets = fixed_args$nsims)
}
sc_opt <- self_calib_adaptive(calib_generator, backend_binom_opt, updator, "eta", lambda_mu, lambda_sigma, nsims, tol, fixed_args = fixed_args_binom)
#sc_hmc <- self_calib_adaptive(calib_generator, backend_binom_hmc, updator, "eta", lambda_mu, lambda_sigma, nsims, tol, fixed_args = fixed_args_binom)

plot_rank_hist(sc_opt)
```

```{R}
generator_binom_gmm <- function(lambda_mu, lambda_sigma, fixed_args){
  # fixed value across simulated datasets
  ## meta
  nobs <- fixed_args$nobs
  nsims <- fixed_args$nsims
  link_type <- fixed_args$link_type
  
  # predictor
  if("X" %in% names(fixed_args)) {X <- fixed_args$X} else X = 0
  # parameter with fixed distribution across `nsims` datasets
  if("b" %in% names(fixed_args)) {b <- fixed_args$b}  else b = 0
  # target variable updated at each iteration
  
  # generate
  eta <- draws_of(rvar_rng(rnorm, n = 1, mean = lambda_mu, sd=lambda_sigma, ndraws = nsims)  + X %**% b)
  mu <- invtf_param_vec(eta, link_type = link_type)
 
  Y <- rvar_rng(rbinom, n = nobs, size = nsize, prob = mu, ndraws = nsims)
  gen_rvars <- draws_rvars(nsims = nsims, nobs = nobs, nsize = nsize, link = link_type,
                           lambda_mu = lambda_mu, lambda_log_sigma = log(lambda_sigma), 
                           Y = Y)
  SBC_datasets(
    parameters = as_draws_matrix(list(eta = eta)), 
    generated = draws_rvars_to_standata(gen_rvars)
  )
}
# step1: prior predictvie sampling
fixed_args_binom <- list(nobs = nobs, nsims = nsims, nsize = nsize, link_type = 1, ndraws=100)
lambda_mu_gmm <- rvar(array(rep(rnorm(nsims, 2, 5), each = nsims), dim = c(nsims, nsims)))
lambda_sigma_gmm <- rvar(array(rep(10, nsims), dim=c(nsims, 1)))
datasets <- generator_binom_gmm(lambda_mu_gmm, lambda_sigma_gmm, fixed_args_binom)
cmdstan_binom_mod <- cmdstanr::cmdstan_model("models/binom-laplace_gmm.stan")
rstan_binom_mod <- stan_model("models/binom-laplace_gmm.stan")
backend_binom_hmc_gmm <- SBC_backend_cmdstan_sample(cmdstan_binom_mod, chains = 4, iter_sampling = ndraws / 4) 
backend_binom_opt <- SBC_backend_rstan_optimizing(rstan_binom_mod, draws = ndraws)
sc_opt <- self_calib_adaptive(generator_binom_gmm, backend_binom_opt, updator, "eta", lambda_mu_gmm, lambda_sigma_gmm, nsims, tol, fixed_args = fixed_args_binom)

sc_hmc <- self_calib_adaptive(generator_binom_gmm, backend_binom_opt, updator, "eta", lambda_mu_gmm, lambda_sigma_gmm, nsims, tol, fixed_args = fixed_args_binom)
```
