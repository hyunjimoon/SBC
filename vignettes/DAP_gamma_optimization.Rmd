---
title: "self-calibration-adaptive"
author: "Hyunji Moon, Shinyoung Kim"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE, warning=FALSE}
library(SBC)
library(cmdstanr)
library(parallel)
library(bayesplot)
library(posterior)
library(dplyr)
library(rstan)
library(future)
library(ggpubr)
library(rstanarm)
library(ggplot2)
library(mclust)
library(plot3D)
options(mc.cores = parallel::detectCores())
options(SBC.min_chunk_size = 5)
#set.seed(1984)
```


```{R, warning=FALSE, error=FALSE}
## Generator settings
# number of SBC simulations per iteration (generator)
nsims <- 200

# number of observations
nobs <- 10

# link function (1 = logit, 2 = probit, 3 = cloglog)
link <- 1

# number of binomial trials per observation
nsize <- 10

## Backend settings
# number of draws per posterior approximation 
ndraws <- 100

# number of chains for hmc posterior approximation
nchains <- 2
```

```{R}
generator_gr <- function(lambdas, fixed_args){
  # fixed value across simulated datasets
  ## meta
  nobs <- fixed_args$nobs
  K <- fixed_args$K
  dist_types <- fixed_args$dist_types
  while(TRUE){
    # predictor
    X <- array(rnorm(nobs * K, mean = 1, sd = 0.5), dim = c(nobs, K))
    b <- rnorm(K, mean = 0, sd = 1)
    # generate
    lambda_arg1 <- c()
    lambda_arg2 <- c()
    if(dist_types$shape == "normal"){
      shape <- rnorm(1, mean = lambdas$shape$mu, sd=lambdas$shape$sigma)
      lambda_arg1 <- c(lambda_arg1, lambdas$shape$mu)
      lambda_arg2 <- c(lambda_arg2, lambdas$shape$sigma)
    }
    else if(dist_types$shape == "gamma"){
      shape <- rgamma(1, shape = lambdas$shape$alpha, rate = lambdas$shape$beta)
      lambda_arg1 <- c(lambda_arg1, lambdas$shape$alpha)
      lambda_arg2 <- c(lambda_arg2, lambdas$shape$beta)
    }
    else if(dist_types$shape == "lognormal"){
      shape <- rlnorm(1, meanlog = lambdas$shape$mu, sdlog = lambdas$shape$sigma)
      lambda_arg1 <- c(lambda_arg1, lambdas$shape$mu)
      lambda_arg2 <- c(lambda_arg2, lambdas$shape$sigma)
    }
    
    if(dist_types$a == "normal"){
      a <- rnorm(1, mean = lambdas$a$mu, sd=lambdas$a$sigma)
      lambda_arg1 <- c(lambda_arg1, lambdas$a$mu)
      lambda_arg2 <- c(lambda_arg2, lambdas$a$sigma)
    }
    #a <- rnorm(1, mean = 2, sd = 5)
    logmu <- as.numeric(a + X %*% b)
    mu <- exp(logmu)
    Y <- rgamma(nobs, shape = shape, rate = shape / mu)
    
    if(!any(Y <= 1e-32)){
      return(list(
              parameters = list(shape = shape),
              generated = list(nobs= nobs, K = K, X = X, dist_types = match(unlist(dist_types), c("normal", "gamma", "lognormal")), 
                               lambda_arg1 = lambda_arg1, lambda_arg2 = lambda_arg2, Y = Y)
              )
             )
    }
  }
}

fixed_args_gr <- list(nobs = nobs, K = 15, nsims = nsims, dist_types=list(shape="lognormal", a="normal"))
cmdstan_mod_gr <- cmdstanr::cmdstan_model("models/gamma-reg.stan")
rstan_mod_gr <- stan_model("models/gamma-reg.stan")
backend_gr_opt <- SBC_backend_rstan_optimizing(rstan_mod_gr, draws = ndraws)
backend_gr_hmc <- SBC_backend_cmdstan_sample(cmdstan_mod_gr, chains = nchains, iter_sampling = ndraws / nchains) 

# combines target hp values with other hyperparameter settings
calib_generator <- function(lambda_init_gamma, fixed_args){
  generate_datasets(SBC_generator_function(generator_gr, lambda_init_gamma, fixed_args), n_datasets = fixed_args_gr$nsims)
}

calculate_dap <- function(mu, var, generator, backened, fixed_args){
  lambda_init_gamma <- list(
    shape = list(mu= mu, sigma = sqrt(var)), #list(alpha= mu^2 / var, beta= mu / var),
    a = list(mu= 2, sigma = 1)
  )
  datasets <- do.call(generator, list(lambda_init_gamma, fixed_args = fixed_args))
  sbc_result <- compute_results(datasets, backened, thin_ranks = 1)
  draws_eta <- c()
  draws_Y <- c()
  for(i in 1:nsims){
    draws_Y <- c(draws_Y, datasets$generated[[i]]$Y)
  }
  for(fit in sbc_result$fits){
    samples <- SBC_fit_to_draws_matrix(fit)
    draws_eta <- c(draws_eta, posterior::extract_variable(samples, "shape"))
  }
  # assume normal for dap
  mu <- mean(draws_eta)
  var <- sd(draws_eta)^2
  # gamma_est <- MASS::fitdistr(draws_eta, "gamma", start=list(shape=1, rate=1))$estimate
  # alpha <- as.numeric(gamma_est["shape"])
  # beta <- as.numeric(gamma_est["rate"])
  # mu = alpha / beta
  # var = alpha / beta^2
  return(list(mu=mu, var=var, draws_eta=draws_eta, draws_Y=draws_Y))
}
```

##

```{r}
gridsize <- 5
mu_seq <- seq(1, 3, length.out = gridsize)
var_seq <- seq(1, 2, length.out = gridsize)
grid_size <- length(mu_seq) * length(var_seq)

squared_lambda_diff <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
rownames(squared_lambda_diff) <- mu_seq
colnames(squared_lambda_diff) <- var_seq

lambda_diff <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
rownames(lambda_diff) <- mu_seq
colnames(lambda_diff) <- var_seq

dap_lambda_mu <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
dap_lambda_var <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
rownames(dap_lambda_mu) <- mu_seq
rownames(dap_lambda_var) <- mu_seq
colnames(dap_lambda_mu) <- var_seq
colnames(dap_lambda_var) <- var_seq

lambda_mu <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
lambda_var <- array(rep(NA, length(mu_seq) * length(var_seq)), dim = c(length(mu_seq), length(var_seq)))
rownames(lambda_mu) <- mu_seq
rownames(lambda_var) <- mu_seq
colnames(lambda_mu) <- var_seq
colnames(lambda_var) <- var_seq

generated_Y <- array(rep(NA, nsims * nobs * gridsize * gridsize), dim=c(nsims * nobs, gridsize, gridsize) )
dimnames(generated_Y)[[2]] <- mu_seq
dimnames(generated_Y)[[3]] <- var_seq
for(i in 1:length(mu_seq)){
  for(j in 1:length(var_seq)){
    dap <- calculate_dap(mu_seq[[i]],var_seq[[j]] , calib_generator, backend_gr_opt, fixed_args_gr)
    squared_lambda_diff[i,j] <- sqrt((mu_seq[[i]] - dap$mu)^2 + (var_seq[[j]] - dap$var)^2)
    lambda_diff[i,j] <- (dap$mu - mu_seq[[i]]) + (dap$var - var_seq[[j]])
    dap_lambda_mu[i, j] <- dap$mu
    dap_lambda_var[i, j] <- dap$var
    lambda_mu[i, j] <- mu_seq[[i]]
    lambda_var[i, j] <- var_seq[[j]]
    generated_Y[, i, j] <- dap$draws_Y
  }
}
saved_dap <- new.env()
saved_dap[["gridsize"]] <- gridsize
saved_dap[["grid_size"]] <- grid_size
saved_dap[["squared_lambda_diff"]] <- squared_lambda_diff
saved_dap[["lambda_diff"]] <- lambda_diff
saved_dap[["dap_lambda_mu"]] <- dap_lambda_mu
saved_dap[["dap_lambda_var"]] <- dap_lambda_var
saved_dap[["lambda_mu"]] <- lambda_mu
saved_dap[["lambda_var"]] <- lambda_var
saved_dap[["generated_Y"]] <- generated_Y
save(saved_dap, file="dap_backup.Rdata")

# use load("dap_backup.Rata") if you want to load computed dap instead of running this chunk

```


```{R}
persp3D(x=mu_seq, y=var_seq, z = squared_lambda_diff, theta=90, phi=10, xlab="mu", ylab="var", zlab="convex if ", ticks=5, ticktype="detailed")

```
```{R}
persp3D(x=mu_seq, y=var_seq, z=lambda_diff, theta=90, phi=10, ticks=5, ticktype="detailed")
```

Define objective and constraint functions

```{R}
# maximize entropy
# partial derivative is: -log p_w - 1
calc_entropy <- function(p){
  return(as.numeric((p + 1e-8) %*% -log(p + 1e-8)) - 1000 * (sum(p) - 1)^2)
}

calc_entropy_grad <- function(p){
  return(-log(p + 1e-8) - 1 - 2000 * (p + 1e-8))
}

calc_mse <- function(p){
  mean((p *(dap_lambda_mu - lambda_mu))^2 + (p *(dap_lambda_var - lambda_var))^2)
}
calc_mse_grad  <- function(p){
  n_p = length(p)
  (2 * (p *(dap_lambda_mu - lambda_mu) * (dap_lambda_mu - lambda_mu)) + (2 * (p *(dap_lambda_var - lambda_var)) * (dap_lambda_var - lambda_var))) / n_p
}

calc_mse2 <- function(p){
  n <- length(p)
  p <- array(p, dim=c(1, n))
  dap_lambda_mu_vec <- array(dap_lambda_mu, dim=c(1, n))
  dap_lambda_var_vec <- array(dap_lambda_var, dim=c(1, n))
  lambda_mu_vec <- array(lambda_mu, dim=c(1, n))
  lambda_var_vec <- array(lambda_var, dim=c(1, n))
  
  estimator_mu_vec <- p * t(dap_lambda_mu_vec - lambda_mu_vec)  # dim(1, n)
  estimator_var_vec <- p * t(dap_lambda_var_vec - lambda_var_vec)
  
  bias_squared_term <- mean(estimator_mu_vec)^2 + mean(estimator_var_vec)^2
  
  variance_term <- (var(estimator_mu_vec) + var(estimator_var_vec)) * (n - 1)/n
  return(bias_squared_term)# + variance_term)
}

calc_mse2_grad <- function(p){
  n <- length(p)
  p <- array(p, dim=c(1, n))
  dap_lambda_mu_vec <- array(dap_lambda_mu, dim=c(1, n))
  dap_lambda_var_vec <- array(dap_lambda_var, dim=c(1, n))
  lambda_mu_vec <- array(lambda_mu, dim=c(1, n))
  lambda_var_vec <- array(lambda_var, dim=c(1, n))
  
  const_mu_vec <- (dap_lambda_mu_vec - lambda_mu_vec)  # dim(1, n)
  const_var_vec <- (dap_lambda_var_vec - lambda_var_vec)
  
  
  bias_square_grad_mu <- (2 * t(p) %*% const_mu_vec %*% t(const_mu_vec)) / n^2
  bias_square_grad_var <- (2 * t(p) %*% const_var_vec %*% t(const_var_vec)) / n^2
  
  
  #var_grad_mu <- 2/n_p * (p * dap_lambda_mu_vec - mean(p * dap_lambda_mu_vec)) * (dap_lambda_mu_vec - dap_lambda_mu_vec/n_p)
  
  var_grad_mu <- (2 * (p * dap_lambda_mu_vec - mean(p * dap_lambda_mu_vec)) * (dap_lambda_mu_vec - dap_lambda_mu_vec/n)) / n
  var_grad_lambda <- (2 * (p * dap_lambda_var_vec - mean(p * dap_lambda_var_vec)) * (dap_lambda_var_vec - dap_lambda_var_vec/n)) / n
  return(bias_square_grad_mu + bias_square_grad_var)# + var_grad_mu + var_grad_lambda)
    
  
  # grad backup (bias^2 + var)
  #2 * sum(p2 * diff) * diff + 2 * (t_lambda - sum(p2 * t_lambda)) * -(p2 * t_lambda) + (t_lambda - sum(p2 * t_lambda))^2
}

# equal to minimize negative entropy
neg_entropy <- function(p){
  return(-calc_entropy(p))
}

neg_entropy_grad <- function(p){
  return(-calc_entropy_grad(p))
}

theta <- 14
# partial derivative is squared_lambda_diff_{w}
p_v_product_constraint <- function(p){
  # equality constraint should equal 0
  return(as.numeric(p %*% as.vector(squared_lambda_diff)) - 5)
}

p_v_product_constraint_grad <- function(p){
  return(as.vector(squared_lambda_diff))
}

probability_simplex_constraint <- function(p){
  return(sum(p) - 1)
}

probability_simplex_constraint_grad <- function(p){
  return(rep(1, length(p)))
}

# calculate theta and p_init


prob_ineq_constraints <- function(p){
  #constraints <- c(p_v_product_constraint(p), probability_simplex_constraint(p))
  #grad <- c(p_v_product_constraint_grad(p), probability_simplex_constraint_grad(p))
  constraints <- c(p_v_product_constraint(p))
  grad <- c(p_v_product_constraint_grad(p))
  return( list(constraints=constraints, jacobian=grad) )
}

prob_eq_constraints <- function(p){
  constraints <- c(probability_simplex_constraint(p))
  grad <- c(probability_simplex_constraint_grad(p))
  return( list(constraints=constraints, jacobian=grad) )
}

mse2_eq_constraints <- function(p){
  N <- length(p)
  n <- N/2
  constraints <- c()
  jacobian <- array(rep(NA * N * (n+2)), dim=c(n+2, N))
  
  for(i in 1:n){
    constraints[i] <- p[i] - p[n + i]
    grad_vec <- rep(0, N)
    grad_vec[i] <- 1
    grad_vec[n + i] <- -1
    jacobian[i, ]  <- grad_vec
  }
  constraints[length(constraints) + 1] <- sum(p[1:n]) - 1
  jacobian[i+1, ] <- c(rep(1, n), rep(0, n))
  
  constraints[length(constraints) + 1] <- sum(p[(n+1):N]) - 1
  jacobian[i + 2, ] <- c(rep(0, n), rep(1, n))
  return( list(constraints=constraints, jacobian=jacobian) )
}

#If you want to use equality constraints, then you should use one of these algorithms NLOPT_LD_AUGLAG, NLOPT_LN_AUGLAG, NLOPT_LD_AUGLAG_EQ, NLOPT_LN_AUGLAG_EQ, NLOPT_GN_ISRES, NLOPT_LD_SLSQP


# start at uniform
p_init <- as.numeric(c(rep(1e-8, grid_size - 1), 1))

prob_lb <- rep(0.0, length(p_init))
prob_ub <- rep(1.0, length(p_init))

probability_simplex_opts <- list(algorithm="NLOPT_LD_SLSQP", print_level=1, xtol_rel=1e-8, maxeval=1000, check_derivatives=TRUE)
prob_opt <- nloptr::nloptr(p_init, 
                           neg_entropy, 
                           eval_grad_f = neg_entropy_grad, 
                           eval_g_ineq = prob_ineq_constraints, 
                           opts = probability_simplex_opts, 
                           lb=prob_lb, ub=prob_ub)


local_opts <- list(algorithm="NLOPT_LD_LBFGS", xtol_rel = 1.0e-8)
penalty_opts <- list(algorithm="NLOPT_LD_AUGLAG_EQ", print_level=1, xtol_rel=1e-8, maxeval=200, check_derivatives=TRUE, local_opts=local_opts)
mse_opts <- nloptr::nloptr(rep(1 / length(p_init), length(p_init)),
                               calc_mse,
                               eval_grad_f = calc_mse_grad,
                               eval_g_eq = prob_eq_constraints,
                               opts = penalty_opts,
                               lb=prob_lb, ub=prob_ub)


local_opts <- list(algorithm="NLOPT_LD_LBFGS", xtol_rel = 1.0e-8)
penalty_opts <- list(algorithm="NLOPT_LD_AUGLAG_EQ", print_level=1, xtol_rel=1e-8, maxeval=100, check_derivatives=TRUE, local_opts=local_opts)
mse_opts2 <- nloptr::nloptr(rep(1 / length(p_init), length(p_init)),
                               calc_mse2,
                               eval_grad_f = calc_mse2_grad,
                               eval_g_eq = prob_eq_constraints,
                               opts = penalty_opts,
                               lb=prob_lb, ub=prob_ub)

```

```{R}

result_out <- array(prob_opt$solution, dim = c(length(mu_seq), length(var_seq)))
rownames(result_out) <- mu_seq
colnames(result_out) <- var_seq
persp3D(x=mu_seq, y=var_seq, z = result_out, theta=25, phi=10, xlab="mu", ylab="var", zlab="prob_opt_result", ticks=5, ticktype="detailed")
persp3D(x=mu_seq, y=var_seq, z = squared_lambda_diff, theta=25, phi=10, xlab="mu", ylab="var", zlab="convex if ", ticks=5, ticktype="detailed")
```
```{R}
result_dot_out <- array(min_sum_opts$solution, dim = c(length(mu_seq), length(var_seq)))
rownames(result_dot_out) <- mu_seq
colnames(result_dot_out) <- var_seq
persp3D(x=mu_seq, y=var_seq, z = result_dot_out, theta=25, phi=10, xlab="mu", ylab="var", zlab="prob_opt_result", ticks=5, ticktype="detailed")
```


```{R}
N = 10000
sampled_probs <- sample(1:grid_size, N, prob=as.vector(result_out), replace=TRUE)
mu <- rep(mu_seq, length(var_seq))
sigma <- rep(var_seq, each=length(mu_seq))
combined <- data.frame(mu=mu, sigma=sigma)
thetas <- c()
for(i in 1:N){
  thetas[i] <- rnorm(1, combined[sampled_probs[i], "mu"], combined[sampled_probs[i], "sigma"])
}
hist(thetas, probability=TRUE, breaks=30)
```


```{R}
library(ggnewscale)
n_bins = gridsize
lambdas <- data.frame(mu=numeric(), var=numeric(), density_entropy=numeric())
for(i in 1:gridsize){
  for(j in 1:gridsize){
    lambdas[nrow(lambdas) + 1,] = list(mu=rownames(result_out)[i], var=colnames(result_out)[j], density_entropy=result_out[i, j])
  }
}
aggregated <- aggregate(lambdas$density_entropy, by=list(mu=lambdas$mu, var=lambdas$var), FUN=sum)
colnames(aggregated)[3] <- "density_entropy"

lambdas_min_sum <- data.frame(mu=numeric(), var=numeric(), density_point=numeric())
for(i in 1:gridsize){
  for(j in 1:gridsize){
    lambdas_min_sum[nrow(lambdas_min_sum) + 1,] = list(mu=rownames(result_dot_out)[i], var=colnames(result_dot_out)[j], density_point=result_dot_out[i, j])
  }
}
aggregated_min_sum <- aggregate(lambdas_min_sum$density_point, by=list(mu=lambdas_min_sum$mu, var=lambdas_min_sum$var), FUN=sum)
colnames(aggregated_min_sum)[3] <- "density_point"

squared_lambda_diff_df <- data.frame(mu=numeric(), var=numeric(), distance=numeric())
for(i in 1:gridsize){
  for(j in 1:gridsize){
    squared_lambda_diff_df[nrow(squared_lambda_diff_df) + 1,] = list(mu=rownames(squared_lambda_diff)[i], var=colnames(squared_lambda_diff)[j], distance=squared_lambda_diff[i, j])
  }
}
aggregated_squared_lambda_diff <- aggregate(squared_lambda_diff_df$distance, by=list(mu=squared_lambda_diff_df$mu, var=squared_lambda_diff_df$var), FUN=sum)
colnames(aggregated_squared_lambda_diff)[3] <- "distance"
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
aggregated_squared_lambda_diff$distance <- range01(aggregated_squared_lambda_diff$distance)

aggregated$density_point <- aggregated_min_sum$density_point

scaleFUN <- function(x) sprintf("%.2f", as.numeric(x))
ggplot(mapping=aes(x, y)) + geom_tile(data=aggregated, mapping=aes(x=mu, y=var, alpha=density_entropy), fill="goldenrod1") +
  new_scale("alpha") + geom_tile(data=aggregated, mapping=aes(x=mu, y=var, alpha=density_point), fill="dodgerblue3") +
  new_scale("alpha") + geom_tile(data=aggregated_squared_lambda_diff, mapping=aes(x=mu, y=var, alpha=distance), fill = "brown1") +
  xlab("mu") + ylab("sigma") + scale_x_discrete(labels=scaleFUN) + scale_y_discrete(labels=scaleFUN)


ggplot(mapping=aes(x, y)) + geom_tile(data=aggregated, mapping=aes(x=mu, y=var, alpha=density_point), fill="dodgerblue3") +
  new_scale("alpha") + geom_tile(data=aggregated_squared_lambda_diff, mapping=aes(x=mu, y=var, alpha=distance), fill = "brown1") +
  xlab("mu") + ylab("sigma") + scale_x_discrete(labels=scaleFUN) + scale_y_discrete(labels=scaleFUN)

ggplot(mapping=aes(x, y)) + geom_tile(data=aggregated, mapping=aes(x=mu, y=var, alpha=density_entropy), fill="goldenrod1") +
  new_scale("alpha") + geom_tile(data=aggregated_squared_lambda_diff, mapping=aes(x=mu, y=var, alpha=distance), fill = "brown1") +
  xlab("mu") + ylab("sigma") + scale_x_discrete(labels=scaleFUN) + scale_y_discrete(labels=scaleFUN)
```
